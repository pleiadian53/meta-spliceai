#!/usr/bin/env python3
"""
Comprehensive Score-Shifting Validation Test

Tests the score-shifting coordinate adjustment on a diverse set of protein-coding genes
to ensure it works correctly across:
- Different gene sizes (small, medium, large)
- Different strands (+ and -)
- Different chromosomes
- Different splice site densities

Expected: F1 >= 0.7 for most genes (SpliceAI's documented performance)
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parents[2]))

import polars as pl
import logging
from typing import Dict, List

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


def get_test_genes() -> List[Dict]:
    """
    Get a diverse set of protein-coding genes for comprehensive testing.
    
    Selection criteria:
    - Different sizes (small: <10kb, medium: 10-50kb, large: >50kb)
    - Different strands (+ and -)
    - Different chromosomes
    - Well-annotated (known genes with good annotation quality)
    """
    return [
        # Small genes (<10kb)
        {'gene_id': 'ENSG00000134202', 'gene_name': 'GSTM3', 'length': 7107, 'chr': '1', 'strand': '+', 'size': 'small'},
        {'gene_id': 'ENSG00000198804', 'gene_name': 'MT-CO1', 'length': 1542, 'chr': 'MT', 'strand': '+', 'size': 'small'},
        {'gene_id': 'ENSG00000142192', 'gene_name': 'APP', 'length': 290144, 'chr': '21', 'strand': '-', 'size': 'small'},  # Note: APP is actually large, using as test
        
        # Medium genes (10-50kb)
        {'gene_id': 'ENSG00000141510', 'gene_name': 'TP53', 'length': 25768, 'chr': '17', 'strand': '-', 'size': 'medium'},
        {'gene_id': 'ENSG00000171862', 'gene_name': 'PTEN', 'length': 105338, 'chr': '10', 'strand': '+', 'size': 'medium'},
        {'gene_id': 'ENSG00000133703', 'gene_name': 'KRAS', 'length': 45716, 'chr': '12', 'strand': '-', 'size': 'medium'},
        
        # Large genes (>50kb)
        {'gene_id': 'ENSG00000157764', 'gene_name': 'BRAF', 'length': 205603, 'chr': '7', 'strand': '-', 'size': 'large'},
        {'gene_id': 'ENSG00000139618', 'gene_name': 'BRCA2', 'length': 84195, 'chr': '13', 'strand': '+', 'size': 'large'},
        {'gene_id': 'ENSG00000012048', 'gene_name': 'BRCA1', 'length': 81189, 'chr': '17', 'strand': '-', 'size': 'large'},
    ]


def load_gtf_annotations(gene_id: str) -> pl.DataFrame:
    """Load GTF annotations for a gene."""
    gtf_path = Path("data/ensembl/Homo_sapiens.GRCh38.112.gtf")
    if not gtf_path.exists():
        raise FileNotFoundError(f"GTF file not found: {gtf_path}")
    
    # Read GTF and filter for this gene
    import subprocess
    result = subprocess.run(
        ['grep', gene_id, str(gtf_path)],
        capture_output=True,
        text=True
    )
    
    if not result.stdout:
        logger.warning(f"No GTF entries found for {gene_id}")
        return pl.DataFrame()
    
    # Parse GTF lines to extract splice sites
    splice_sites = []
    for line in result.stdout.strip().split('\n'):
        if '\texon\t' in line:
            parts = line.split('\t')
            chrom = parts[0]
            start = int(parts[3])
            end = int(parts[4])
            strand = parts[6]
            
            # Donor site: end of exon (for + strand) or start of exon (for - strand)
            # Acceptor site: start of exon (for + strand) or end of exon (for - strand)
            if strand == '+':
                splice_sites.append({'position': end, 'splice_type': 'donor', 'strand': strand})
                splice_sites.append({'position': start, 'splice_type': 'acceptor', 'strand': strand})
            else:
                splice_sites.append({'position': start, 'splice_type': 'donor', 'strand': strand})
                splice_sites.append({'position': end, 'splice_type': 'acceptor', 'strand': strand})
    
    if not splice_sites:
        return pl.DataFrame()
    
    return pl.DataFrame(splice_sites)


def evaluate_predictions(predictions_df: pl.DataFrame, annotations_df: pl.DataFrame, 
                        threshold: float = 0.5) -> Dict:
    """Evaluate predictions against GTF annotations."""
    if annotations_df.height == 0:
        return None
    
    # Get annotated splice sites
    donor_sites = set(annotations_df.filter(pl.col('splice_type') == 'donor')['position'].to_list())
    acceptor_sites = set(annotations_df.filter(pl.col('splice_type') == 'acceptor')['position'].to_list())
    
    # Get predicted splice sites
    pred_donors = set(predictions_df.filter(pl.col('donor_score') > threshold)['position'].to_list())
    pred_acceptors = set(predictions_df.filter(pl.col('acceptor_score') > threshold)['position'].to_list())
    
    # Calculate metrics
    donor_tp = len(donor_sites & pred_donors)
    donor_fp = len(pred_donors - donor_sites)
    donor_fn = len(donor_sites - pred_donors)
    
    acceptor_tp = len(acceptor_sites & pred_acceptors)
    acceptor_fp = len(pred_acceptors - acceptor_sites)
    acceptor_fn = len(acceptor_sites - pred_acceptors)
    
    # F1 scores
    donor_p = donor_tp / (donor_tp + donor_fp) if (donor_tp + donor_fp) > 0 else 0
    donor_r = donor_tp / (donor_tp + donor_fn) if (donor_tp + donor_fn) > 0 else 0
    donor_f1 = 2 * donor_p * donor_r / (donor_p + donor_r) if (donor_p + donor_r) > 0 else 0
    
    acceptor_p = acceptor_tp / (acceptor_tp + acceptor_fp) if (acceptor_tp + acceptor_fp) > 0 else 0
    acceptor_r = acceptor_tp / (acceptor_tp + acceptor_fn) if (acceptor_tp + acceptor_fn) > 0 else 0
    acceptor_f1 = 2 * acceptor_p * acceptor_r / (acceptor_p + acceptor_r) if (acceptor_p + acceptor_r) > 0 else 0
    
    overall_tp = donor_tp + acceptor_tp
    overall_fp = donor_fp + acceptor_fp
    overall_fn = donor_fn + acceptor_fn
    overall_p = overall_tp / (overall_tp + overall_fp) if (overall_tp + overall_fp) > 0 else 0
    overall_r = overall_tp / (overall_tp + overall_fn) if (overall_tp + overall_fn) > 0 else 0
    overall_f1 = 2 * overall_p * overall_r / (overall_p + overall_r) if (overall_p + overall_r) > 0 else 0
    
    return {
        'donor_f1': donor_f1,
        'acceptor_f1': acceptor_f1,
        'overall_f1': overall_f1,
        'donor_tp': donor_tp,
        'donor_fp': donor_fp,
        'donor_fn': donor_fn,
        'acceptor_tp': acceptor_tp,
        'acceptor_fp': acceptor_fp,
        'acceptor_fn': acceptor_fn,
    }


def test_gene(gene_info: Dict) -> Dict:
    """Test a single gene."""
    gene_id = gene_info['gene_id']
    gene_name = gene_info['gene_name']
    expected_length = gene_info['length']
    strand = gene_info['strand']
    size_class = gene_info['size']
    
    logger.info(f"\n{'='*80}")
    logger.info(f"Testing {gene_id} ({gene_name})")
    logger.info(f"  Length: {expected_length:,} bp, Strand: {strand}, Size: {size_class}")
    logger.info(f"{'='*80}")
    
    try:
        # Run prediction
        from meta_spliceai.splice_engine.meta_models.workflows.inference.enhanced_selective_inference import EnhancedSelectiveInferenceWorkflow
        
        # Note: EnhancedSelectiveInferenceWorkflow requires config, so we'll use the test infrastructure
        # For now, just check if predictions exist
        pred_file = Path(f"predictions/base_only/{gene_id}/{gene_id}_predictions.parquet")
        
        if not pred_file.exists():
            logger.info(f"  Running prediction...")
            # This will be run by the main test script
            return {'gene_id': gene_id, 'status': 'needs_prediction'}
        
        # Load predictions
        predictions_df = pl.read_parquet(pred_file)
        
        # Check coverage
        actual_positions = predictions_df.height
        coverage_pct = (actual_positions / expected_length) * 100
        
        logger.info(f"\n  üìä Coverage:")
        logger.info(f"    Expected: {expected_length:,} positions")
        logger.info(f"    Actual:   {actual_positions:,} positions")
        logger.info(f"    Coverage: {coverage_pct:.1f}%")
        
        coverage_status = "‚úÖ" if coverage_pct >= 99 else "‚ö†Ô∏è"
        logger.info(f"    Status: {coverage_status}")
        
        # Load annotations
        logger.info(f"\n  üìñ Loading annotations...")
        annotations_df = load_gtf_annotations(gene_id)
        
        if annotations_df.height == 0:
            logger.warning(f"    ‚ö†Ô∏è  No annotations found")
            return {
                'gene_id': gene_id,
                'gene_name': gene_name,
                'strand': strand,
                'size': size_class,
                'coverage': coverage_pct,
                'status': 'no_annotations'
            }
        
        n_donors = len(annotations_df.filter(pl.col('splice_type') == 'donor'))
        n_acceptors = len(annotations_df.filter(pl.col('splice_type') == 'acceptor'))
        logger.info(f"    Found {n_donors} donors, {n_acceptors} acceptors")
        
        # Evaluate
        logger.info(f"\n  üéØ Evaluating alignment...")
        metrics = evaluate_predictions(predictions_df, annotations_df, threshold=0.5)
        
        if metrics:
            logger.info(f"\n  üìà Performance Metrics:")
            logger.info(f"    Donor F1:    {metrics['donor_f1']:.3f} (TP={metrics['donor_tp']}, FP={metrics['donor_fp']}, FN={metrics['donor_fn']})")
            logger.info(f"    Acceptor F1: {metrics['acceptor_f1']:.3f} (TP={metrics['acceptor_tp']}, FP={metrics['acceptor_fp']}, FN={metrics['acceptor_fn']})")
            logger.info(f"    Overall F1:  {metrics['overall_f1']:.3f}")
            
            # Assessment
            f1 = metrics['overall_f1']
            if f1 >= 0.8:
                status = "‚úÖ Excellent"
            elif f1 >= 0.7:
                status = "‚úÖ Good"
            elif f1 >= 0.6:
                status = "‚ö†Ô∏è  Acceptable"
            else:
                status = "‚ùå Poor"
            
            logger.info(f"\n  üéì Assessment: {status}")
            
            return {
                'gene_id': gene_id,
                'gene_name': gene_name,
                'strand': strand,
                'size': size_class,
                'coverage': coverage_pct,
                'donor_f1': metrics['donor_f1'],
                'acceptor_f1': metrics['acceptor_f1'],
                'overall_f1': metrics['overall_f1'],
                'status': 'success'
            }
        else:
            return {
                'gene_id': gene_id,
                'gene_name': gene_name,
                'strand': strand,
                'size': size_class,
                'coverage': coverage_pct,
                'status': 'no_metrics'
            }
    
    except Exception as e:
        logger.error(f"  ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return {
            'gene_id': gene_id,
            'gene_name': gene_name,
            'strand': strand,
            'size': size_class,
            'status': 'error',
            'error': str(e)
        }


def main():
    """Main test function."""
    logger.info("="*80)
    logger.info("COMPREHENSIVE SCORE-SHIFTING VALIDATION TEST")
    logger.info("="*80)
    logger.info("\nObjective: Validate score-shifting on diverse protein-coding genes")
    logger.info("Expected: F1 >= 0.7 for most genes, 100% coverage for all")
    logger.info("")
    
    # Get test genes
    test_genes = get_test_genes()
    
    logger.info(f"Testing {len(test_genes)} genes:")
    logger.info(f"  Small (<10kb):  {sum(1 for g in test_genes if g['size'] == 'small')} genes")
    logger.info(f"  Medium (10-50kb): {sum(1 for g in test_genes if g['size'] == 'medium')} genes")
    logger.info(f"  Large (>50kb):  {sum(1 for g in test_genes if g['size'] == 'large')} genes")
    logger.info(f"  + strand:       {sum(1 for g in test_genes if g['strand'] == '+')} genes")
    logger.info(f"  - strand:       {sum(1 for g in test_genes if g['strand'] == '-')} genes")
    
    # Test each gene
    results = []
    for gene_info in test_genes:
        result = test_gene(gene_info)
        if result:
            results.append(result)
    
    # Summary
    logger.info(f"\n{'='*80}")
    logger.info("SUMMARY")
    logger.info(f"{'='*80}")
    
    # Filter successful results
    successful = [r for r in results if r['status'] == 'success']
    
    if not successful:
        logger.warning("‚ö†Ô∏è  No successful tests to summarize")
        return
    
    # Coverage summary
    logger.info(f"\nCoverage:")
    for r in successful:
        status = "‚úÖ" if r['coverage'] >= 99 else "‚ö†Ô∏è"
        logger.info(f"  {status} {r['gene_name']:10s} ({r['strand']}): {r['coverage']:.1f}%")
    
    avg_coverage = sum(r['coverage'] for r in successful) / len(successful)
    logger.info(f"\n  Average: {avg_coverage:.1f}%")
    
    # Performance by size
    logger.info(f"\nPerformance by Size:")
    for size in ['small', 'medium', 'large']:
        size_results = [r for r in successful if r['size'] == size]
        if size_results:
            avg_f1 = sum(r['overall_f1'] for r in size_results) / len(size_results)
            logger.info(f"  {size.capitalize():10s}: F1={avg_f1:.3f} (n={len(size_results)})")
    
    # Performance by strand
    logger.info(f"\nPerformance by Strand:")
    for strand in ['+', '-']:
        strand_results = [r for r in successful if r['strand'] == strand]
        if strand_results:
            avg_f1 = sum(r['overall_f1'] for r in strand_results) / len(strand_results)
            logger.info(f"  {strand} strand:    F1={avg_f1:.3f} (n={len(strand_results)})")
    
    # Detailed results
    logger.info(f"\nDetailed Results:")
    logger.info(f"{'Gene':<10s} {'Strand':<7s} {'Size':<8s} {'Coverage':<10s} {'Donor F1':<10s} {'Acceptor F1':<12s} {'Overall F1':<12s} {'Status':<10s}")
    logger.info("-" * 100)
    
    for r in successful:
        status = "‚úÖ" if r['overall_f1'] >= 0.7 else "‚ö†Ô∏è"
        logger.info(f"{r['gene_name']:<10s} {r['strand']:<7s} {r['size']:<8s} {r['coverage']:>6.1f}%    "
                   f"{r['donor_f1']:>6.3f}     {r['acceptor_f1']:>6.3f}       {r['overall_f1']:>6.3f}       {status}")
    
    # Overall assessment
    avg_f1 = sum(r['overall_f1'] for r in successful) / len(successful)
    high_f1 = sum(1 for r in successful if r['overall_f1'] >= 0.7)
    full_coverage = sum(1 for r in successful if r['coverage'] >= 99)
    
    logger.info(f"\n{'='*80}")
    logger.info("VERDICT")
    logger.info(f"{'='*80}")
    logger.info(f"  Genes tested:        {len(successful)}")
    logger.info(f"  Average F1:          {avg_f1:.3f}")
    logger.info(f"  F1 >= 0.7:           {high_f1}/{len(successful)} ({100*high_f1/len(successful):.0f}%)")
    logger.info(f"  Coverage >= 99%:     {full_coverage}/{len(successful)} ({100*full_coverage/len(successful):.0f}%)")
    
    if avg_f1 >= 0.7 and full_coverage >= 0.8 * len(successful):
        logger.info(f"\n‚úÖ SUCCESS: Score-shifting validated across diverse genes!")
        logger.info(f"   - Average F1: {avg_f1:.3f} (target: >= 0.7)")
        logger.info(f"   - Coverage: {100*full_coverage/len(successful):.0f}% of genes have full coverage")
        logger.info(f"   - Ready for production use")
    elif avg_f1 >= 0.6:
        logger.info(f"\n‚ö†Ô∏è  PARTIAL SUCCESS: Score-shifting works but below target")
        logger.info(f"   - Average F1: {avg_f1:.3f} (target: >= 0.7)")
        logger.info(f"   - May need further investigation")
    else:
        logger.error(f"\n‚ùå FAILURE: Score-shifting not working correctly")
        logger.error(f"   - Average F1: {avg_f1:.3f} (target: >= 0.7)")
        logger.error(f"   - Review implementation")
    
    logger.info("="*80)
    
    # Save results
    output_path = Path("results/score_shifting_comprehensive_test.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    import json
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    logger.info(f"\nüìÅ Results saved to: {output_path}")


if __name__ == "__main__":
    main()

