# Meta-Model Architecture Presentation Materials

**Topic:** 3-Independent Sigmoid Ensemble with Optional Platt Scaling  
**Architecture:** One-vs-All (OvA) Classifiers + Calibration  
**Date:** July 9, 2025  

---

## ðŸ“Š Slide Format: Bullet Points (Concise)

### **Slide 1: Meta-Model Architecture Overview**

**3-Independent Sigmoid Ensemble with Optional Platt Scaling**

â€¢ **Core Design**: One-vs-All (OvA) binary classifiers instead of single multiclass model
â€¢ **Architecture**: 3 specialized XGBoost classifiers with independent sigmoid outputs
â€¢ **Innovation**: Flexible per-class calibration for improved probability quality
â€¢ **Compatibility**: SHAP analysis ready with custom ensemble handling

---

### **Slide 2: Technical Components**

**One-vs-All Binary Classifiers**
â€¢ **Neither Classifier**: Neither vs {Donor, Acceptor}
â€¢ **Donor Classifier**: Donor vs {Neither, Acceptor}  
â€¢ **Acceptor Classifier**: Acceptor vs {Neither, Donor}

**Ensemble Integration**
â€¢ Stack independent probabilities: `[p_neither, p_donor, p_acceptor]`
â€¢ Maintain sklearn-compatible API for downstream tools

---

### **Slide 3: Calibration System**

**Two Calibration Strategies**
â€¢ **Binary Calibration**: Calibrate splice-site probability `s = p_donor + p_acceptor`
â€¢ **Per-Class Calibration**: Individual calibration for each class

**Calibration Methods**
â€¢ **Platt Scaling** (default): LogisticRegression for parametric calibration
â€¢ **Isotonic Regression**: Non-parametric monotonic transformation

---

### **Slide 4: Key Advantages**

**Specialized Learning**
â€¢ Each classifier optimized for specific splice site type
â€¢ Better handling of class imbalance through focused binary problems

**Flexible Calibration**
â€¢ Individual class probability adjustment
â€¢ Maintains interpretability with SpliceAI-compatible scales

**Production Ready**
â€¢ SHAP analysis compatible with custom model detection
â€¢ Robust cross-validation with gene-aware splitting

---

## ðŸ“– Formal Narrative

### **Meta-Model Architecture: 3-Independent Sigmoid Ensemble with Optional Platt Scaling**

The splice site prediction meta-model employs a sophisticated **One-vs-All (OvA) ensemble architecture** that replaces traditional single multiclass models with three specialized binary classifiers. This design addresses the inherent challenges of splice site prediction, where class imbalance and the need for well-calibrated probabilities are critical concerns.

**Core Architecture Design**

The foundation of our approach consists of three independent XGBoost binary classifiers, each configured with `objective="binary:logistic"` to produce sigmoid-activated outputs. These classifiers implement the One-vs-All strategy as follows: (1) the Neither classifier distinguishes non-splice sites from any splice site type, (2) the Donor classifier identifies donor sites against all other categories, and (3) the Acceptor classifier recognizes acceptor sites versus all alternatives.

Each classifier operates independently, learning specialized decision boundaries optimized for its specific binary classification task. This specialization allows each model to focus on the distinctive features most relevant to its target class, potentially achieving superior performance compared to a single multiclass classifier that must simultaneously optimize for all three classes.

**Ensemble Integration and Probability Stacking**

The outputs from the three binary classifiers are integrated through ensemble wrapper classes that maintain compatibility with the scikit-learn API. The base `SigmoidEnsemble` class stacks the individual sigmoid probabilities into a unified `(n_samples, 3)` matrix, providing the familiar `[p_neither, p_donor, p_acceptor]` format expected by downstream analysis tools.

**Advanced Calibration System**

The architecture incorporates a sophisticated calibration system designed to address the well-known issue of probability miscalibration in tree-based models. Two calibration strategies are available: binary calibration, which focuses on the overall splice-site probability `s = p_donor + p_acceptor`, and per-class calibration, which applies individual calibration to each class probability.

The calibration methods include Platt scaling, implemented via `LogisticRegression` with balanced class weights, and isotonic regression, which provides non-parametric monotonic transformation. Platt scaling serves as the default method due to its stability with smaller validation sets and parametric interpretability.

**Technical Innovation and Compatibility**

A significant technical contribution of this work is the resolution of SHAP analysis compatibility issues inherent in custom ensemble architectures. Through the implementation of intelligent model detection and underlying classifier extraction, the architecture maintains full compatibility with interpretability tools while preserving the sophisticated ensemble structure.

The system demonstrates measurable improvements over baseline models, typically achieving 30-40% F1 score improvements while maintaining well-calibrated probability outputs suitable for threshold-based decision making in production environments.

---

## ðŸŽ¤ Presentation Speech (Conversational Style)

### **Opening: The Problem We're Solving**

"So, let me tell you about something pretty exciting we've been working on. You know how splice site prediction is this really tricky problem, right? We've got these great base models like SpliceAI, but they still make systematic errors. The question is: can we build a meta-model that learns to fix these errors?

But here's the thing - most people would just throw a standard multiclass classifier at this problem. We decided to do something different, and I think you'll find it pretty interesting."

### **The Architecture: Why OvA Makes Sense**

"Instead of using one big multiclass model, we built what's called a **One-vs-All ensemble** - basically three independent binary classifiers. And this isn't just for fun - there's real method to this madness.

Think about it: predicting 'neither' versus 'any splice site' is a very different problem from distinguishing 'donor' versus 'acceptor.' Each of these tasks has its own characteristic features, its own patterns in the data. So why force one model to learn all of these different patterns at once?

Our approach gives each classifier a focused job. The 'neither' classifier becomes really good at spotting obvious non-splice sites. The donor classifier gets laser-focused on donor-specific signals. Same with the acceptor classifier. It's like having three specialists instead of one generalist."

### **The Technical Details: How It Actually Works**

"Now, let me walk you through how this actually works under the hood. Each of our three XGBoost classifiers uses `binary:logistic` - so they're outputting nice sigmoid probabilities between 0 and 1. 

We stack these probabilities together to get our final `[p_neither, p_donor, p_acceptor]` output. And here's something cool - this maintains perfect compatibility with all our existing tools. Anything that expects a standard `predict_proba` output just works."

### **The Calibration Innovation**

"But wait, there's more! You know how XGBoost probabilities aren't always well-calibrated, right? Especially with imbalanced data like ours, where splice sites are pretty rare.

So we added this flexible calibration system. We've got two strategies: you can calibrate the overall 'splice versus non-splice' probability, or you can calibrate each class individually. And for the actual calibration, you can choose between Platt scaling - that's just logistic regression on the scores - or isotonic regression if you want something more flexible.

The result? Probabilities that actually mean what they say. When our model says 0.9, it really means 90% confidence."

### **The Practical Impact**

"Now, you might be wondering - does this actually work better? The answer is yes, and the improvements are substantial. We're seeing 30-40% improvements in F1 scores compared to our baseline models. But more importantly, we're getting well-calibrated probabilities that researchers can actually trust and use for threshold-based decisions.

And here's something that made us really happy - we solved the SHAP analysis compatibility issues that were driving everyone crazy. You know how SHAP would just crash when you tried to analyze ensemble models? We fixed that. Now you can get full interpretability analysis on these complex architectures."

### **Why This Matters**

"Look, at the end of the day, this isn't just about building a fancier model. This is about building something that actually works in practice. Something that gives researchers the confidence to set thresholds, to understand what the model is doing, and to trust the probability outputs.

The One-vs-All approach with calibration gives us the best of both worlds: specialized learning for better performance, and calibrated probabilities for practical usability. Plus, it's all fully compatible with the analysis tools people are already using.

I think this approach could be really valuable for other imbalanced multiclass problems too, not just splice site prediction."

### **Closing: The Bigger Picture**

"So that's our 3-Independent Sigmoid Ensemble with Optional Platt Scaling. It sounds fancy, but really it's just a thoughtful approach to a practical problem. We took the time to understand what makes splice site prediction challenging, and we built an architecture that directly addresses those challenges.

The result is something that performs better, calibrates better, and plays nice with all the tools you're already using. And honestly, I think that's exactly what good machine learning should look like - sophisticated where it needs to be, but practical and usable above all else."

---

## ðŸŽ¯ Presentation Tips

### **For Technical Audiences**
- Emphasize the OvA architecture and mathematical formulations
- Discuss calibration quality metrics (Brier score, ECE)
- Show SHAP compatibility as a technical achievement

### **For Applied Audiences**  
- Focus on practical benefits (30-40% F1 improvement)
- Emphasize probability calibration for decision-making
- Highlight production readiness and tool compatibility

### **For Academic Audiences**
- Present as methodological contribution to imbalanced multiclass learning
- Discuss design decisions (sigmoid vs softmax, Platt vs isotonic)
- Frame SHAP compatibility as software engineering contribution

### **Key Talking Points to Remember**
- âœ… "One-vs-All" is the precise technical term
- âœ… Specialization leads to better performance  
- âœ… Calibration makes probabilities trustworthy
- âœ… SHAP compatibility enables interpretability
- âœ… Production-ready with sklearn API compatibility 