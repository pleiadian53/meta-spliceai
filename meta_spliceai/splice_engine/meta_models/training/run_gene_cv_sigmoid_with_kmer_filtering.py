#!/usr/bin/env python3
"""Gene-wise K-fold CV with optional k-mer filtering.

This is a modified version of run_gene_cv_sigmoid.py that includes
optional k-mer filtering capabilities for handling large feature sets.
"""

from __future__ import annotations

from pathlib import Path
from typing import List, Dict
import argparse
import json
import logging
import os
import random

import numpy as np
import warnings
# Suppress repeated "invalid value encountered in divide" warnings from numpy.corrcoef
warnings.filterwarnings(
    "ignore",
    message=r"invalid value encountered in divide",
    category=RuntimeWarning,
    module=r"numpy",
)
import pandas as pd
import matplotlib.pyplot as plt
from xgboost import XGBClassifier
from sklearn.model_selection import GroupKFold, GroupShuffleSplit
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    confusion_matrix,
    precision_score,
    recall_score,
    top_k_accuracy_score,
    roc_curve,
    precision_recall_curve,
    auc,
    average_precision_score,
)

from meta_spliceai.splice_engine.meta_models.training import datasets
from meta_spliceai.splice_engine.meta_models.builder import preprocessing
from meta_spliceai.splice_engine.meta_models.training.classifier_utils import (
    _encode_labels,
    SigmoidEnsemble,
    PerClassCalibratedSigmoidEnsemble,
)
from meta_spliceai.splice_engine.meta_models.evaluation.viz_utils import (
    plot_roc_pr_curves, check_feature_correlations, plot_combined_roc_pr_curves_meta
)

# Import k-mer filtering functionality
from meta_spliceai.splice_engine.meta_models.features import (
    add_kmer_filtering_args,
    KmerFilterConfig,
    integrate_kmer_filtering_in_cv,
    validate_filtering_config
)

from meta_spliceai.splice_engine.utils_kmer import is_kmer_feature as _is_kmer


################################################################################
# CLI
################################################################################

def _parse_args(argv: List[str] | None = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Gene-wise K-fold CV with optional k-mer filtering.")
    p.add_argument("--dataset", required=True)
    p.add_argument("--out-dir", required=True)

    p.add_argument("--gene-col", default="gene_id")
    p.add_argument("--n-folds", "--n-splits", type=int, default=5, dest="n_folds",
                   help="Number of CV folds (alias: --n-splits)")
    p.add_argument("--valid-size", type=float, default=0.1)
    p.add_argument("--row-cap", type=int, default=100_000)

    # Diagnostics / evaluation
    p.add_argument("--diag-sample", type=int, default=25_000)
    p.add_argument("--annotations", default=None,
                    help="[DEPRECATED] Use --splice-sites-path instead. Kept for backward compatibility.")
    p.add_argument("--neigh-sample", type=int, default=0)
    p.add_argument("--neigh-window", type=int, default=10)
    p.add_argument("--sample-genes", type=int, default=None,
                   help="Sample only a subset of genes for faster testing")

    # Base-vs-meta comparison flags
    p.add_argument("--donor-score-col", default="donor_score",
                   help="Column with raw donor probability from the base model.")
    p.add_argument("--acceptor-score-col", default="acceptor_score",
                   help="Column with raw acceptor probability from the base model.")
    p.add_argument("--splice-prob-col", default="score",
                   help="Optional column that already contains donor+acceptor probability. If present it is preferred.")
    p.add_argument("--base-thresh", type=float, default=0.5,
                   help="Threshold on raw base splice probability (donor+acceptor) to call a splice site.")

    # Model parameters
    p.add_argument("--n-estimators", type=int, default=100)
    p.add_argument("--max-depth", type=int, default=6)
    p.add_argument("--eta", type=float, default=0.3)
    p.add_argument("--subsample", type=float, default=0.8)
    p.add_argument("--colsample-bytree", type=float, default=0.8)
    p.add_argument("--tree-method", default="hist")
    p.add_argument("--device", default="auto")

    # Calibration options
    p.add_argument("--calibrate", action="store_true")
    p.add_argument("--calibrate-per-class", action="store_true")
    p.add_argument("--calib-method", choices=["isotonic", "platt"], default="isotonic")
    p.add_argument("--meta-calibrate", action="store_true")

    # Visualization and analysis
    p.add_argument("--plot-curves", action="store_true", default=True)
    p.add_argument("--no-plot-curves", action="store_true", dest="plot_curves")
    p.add_argument("--plot-format", choices=["pdf", "png", "svg"], default="pdf")
    p.add_argument("--n-roc-points", type=int, default=101)
    p.add_argument("--dpi", type=int, default=300)

    # Feature quality control
    p.add_argument("--check-leakage", action="store_true")
    p.add_argument("--leakage-threshold", type=float, default=0.95)
    p.add_argument("--auto-exclude-leaky", action="store_true")
    p.add_argument("--exclude-features", action="store_true")
    p.add_argument("--leakage-probe", action="store_true")

    # Advanced options
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--verbose", action="store_true")
    p.add_argument("--log-fold-metrics", action="store_true")
    p.add_argument("--monitor-overfitting", action="store_true")
    p.add_argument("--overfitting-threshold", type=float, default=0.05)
    p.add_argument("--early-stopping-patience", type=int, default=30)
    p.add_argument("--convergence-improvement", type=float, default=0.001)

    # Add k-mer filtering arguments
    add_kmer_filtering_args(p)

    return p.parse_args(argv)


def main(argv: List[str] | None = None) -> None:
    args = _parse_args(argv)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s: %(message)s",
    )
    
    # Log important settings
    exclude_file = Path(args.out_dir) / "exclude_features.txt"
    if args.exclude_features or exclude_file.exists():
        sources = []
        if args.exclude_features:
            sources.append("command line")
        if exclude_file.exists():
            sources.append("exclude_features.txt")
        logging.info(f"Feature exclusion enabled from {' and '.join(sources)}")
    
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # Initialize k-mer filtering configuration
    kmer_config = KmerFilterConfig.from_args(args)
    
    # Validate k-mer filtering configuration
    if kmer_config.enabled:
        if not validate_filtering_config(kmer_config):
            logging.error("Invalid k-mer filtering configuration. Exiting.")
            return
        logging.info(f"K-mer filtering enabled with strategy: {kmer_config.strategy}")
    
    # 2. Run K-fold CV with gene grouping
    if args.n_folds > 1 or args.log_fold_metrics:
        print("\nStarting gene-wise K-fold CV...")

    # Handle deprecated --annotations parameter
    if args.annotations and not args.splice_sites_path:
        print("Warning: --annotations is deprecated, please use --splice-sites-path instead")
        args.splice_sites_path = args.annotations

    # honour row-cap via env var used by datasets.load_dataset
    if args.row_cap > 0 and not os.getenv("SS_MAX_ROWS"):
        os.environ["SS_MAX_ROWS"] = str(args.row_cap)

    # 1. Load dataset
    if args.sample_genes is not None:
        # Use gene-level sampling for faster testing
        from meta_spliceai.splice_engine.meta_models.training.label_utils import load_dataset_sample
        print(f"[INFO] Sampling {args.sample_genes} genes from dataset for faster testing")
        df = load_dataset_sample(args.dataset, sample_genes=args.sample_genes, random_seed=args.seed)
    else:
        # Load full dataset
        df = datasets.load_dataset(args.dataset)
        
    if args.gene_col not in df.columns:
        raise KeyError(f"Column '{args.gene_col}' not found in dataset")

    # Prepare data
    genes = df[args.gene_col].values
    feature_names = [col for col in df.columns if col not in [args.gene_col, 'splice_type']]
    X = df[feature_names].values
    y = _encode_labels(df['splice_type'].values)

    # Apply k-mer filtering if enabled
    if kmer_config.enabled:
        print(f"\nüîç Applying k-mer filtering with strategy: {kmer_config.strategy}")
        X, feature_names = integrate_kmer_filtering_in_cv(X, y, feature_names, kmer_config)
    
    # Continue with the rest of the CV process...
    # (This would be the same as the original run_gene_cv_sigmoid.py)
    
    print(f"Dataset shape after filtering: {X.shape}")
    print(f"Feature names: {len(feature_names)}")
    
    # Show k-mer statistics
    kmer_features = [f for f in feature_names if _is_kmer(f)]
    non_kmer_features = [f for f in feature_names if not _is_kmer(f)]
    print(f"K-mer features: {len(kmer_features)}")
    print(f"Non-k-mer features: {len(non_kmer_features)}")
    
    # Save filtering configuration
    if kmer_config.enabled:
        config_info = {
            'enabled': kmer_config.enabled,
            'strategy': kmer_config.strategy,
            'parameters': kmer_config.kwargs,
            'original_features': len(df.columns) - 2,  # -2 for gene_col and splice_type
            'filtered_features': len(feature_names),
            'reduction_percent': (1 - len(feature_names)/(len(df.columns) - 2)) * 100
        }
        
        with open(out_dir / "kmer_filtering_config.json", 'w') as f:
            json.dump(config_info, f, indent=2)
        
        print(f"K-mer filtering configuration saved to: {out_dir / 'kmer_filtering_config.json'}")
    
    print("\n‚úÖ K-mer filtering integration complete!")
    print("This is a demonstration of the integration. The full CV process would continue here.")


if __name__ == "__main__":
    main() 