# SHAP Analysis Compatibility Resolution

**Document Created:** July 9, 2025  
**Last Updated:** July 10, 2025  
**Environment:** `surveyor` conda environment  
**Issue Resolution:** Keras/TensorFlow/SHAP/TorchVision dependency conflicts in gene-aware cross-validation  

## Table of Contents

1. [Problem Description](#problem-description)
2. [Root Cause Analysis](#root-cause-analysis)
3. [Solution Implementation](#solution-implementation)
4. [Library Compatibility Matrix](#library-compatibility-matrix)
5. [Testing and Verification](#testing-and-verification)
6. [Future Maintenance](#future-maintenance)
7. [Technical Implementation Details](#technical-implementation-details)

---

## Problem Description

### Issue Summary

The SHAP (SHapley Additive exPlanations) analysis component in the gene-aware cross-validation pipeline was failing with Keras import errors, preventing the generation of feature importance scores for splice site prediction models.

### Error Symptoms

**Primary Error (Initial):**
```
ModuleNotFoundError: No module named 'keras.__internal__'
```

**Secondary Error (After partial fix):**
```
ModuleNotFoundError: No module named 'keras.src.engine'
Failed to import transformers.modeling_tf_utils because of the following error:
No module named 'keras.src.engine'
```

**Tertiary Error (After Keras fix):**
```
shap.utils._exceptions.InvalidModelError: Model type not yet supported by TreeExplainer: 
<class 'meta_spliceai.splice_engine.meta_models.training.classifier_utils.CalibratedSigmoidEnsemble'>
```

**Quaternary Error (After ensemble fix - July 10, 2025):**
```
RuntimeError: Failed to import transformers.modeling_utils because of the following error:
operator torchvision::nms does not exist

The above exception was the direct cause of the following exception:
RuntimeError: Failed to import transformers.modeling_utils because of the following error:
operator torchvision::nms does not exist
```

**Alternative TorchVision Error Pattern:**
```
RuntimeError: Failed to import transformers.modeling_utils because of the following error:
partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)
```

### Impact

- SHAP analysis completely failed in gene-aware CV pipeline
- Feature importance analysis returned dummy values (0.0001) instead of real SHAP scores
- Loss of model interpretability and feature analysis capabilities
- Pipeline continued but produced misleading results
- Even after Keras compatibility fixes, custom ensemble models blocked SHAP analysis
- **NEW (July 2025)**: TorchVision compatibility issues causing transformers import failures
- **NEW**: Corrupted TorchVision installations causing circular import errors

---

## Root Cause Analysis

### Library Version Conflicts

The issue stemmed from incompatible version combinations between key machine learning libraries:

**Original Environment:**
- TensorFlow: 2.18.0 (very recent)
- Keras: 3.5.0 (very recent, bundled with TF)
- Transformers: 4.48.1 (very recent)
- SHAP: 0.46.0 (older, lacking full Keras 3.x support)

### Technical Root Cause

#### Keras Module Reorganization

1. **Keras 2.13+**: Introduced `keras.__internal__` module for internal components
2. **Keras 3.x**: Restructured internal modules to `keras.src.engine` hierarchy, removed `__internal__`
3. **Transformers Library**: Still attempts to import from both locations depending on version detection

#### Import Chain Failure

The failure occurred in this import chain:
```python
shap.TreeExplainer() 
‚Üí shap.explainers._explainer.py 
‚Üí shap.utils.transformers.is_transformers_lm()
‚Üí transformers.modeling_tf_utils
‚Üí keras.src.engine.base_layer_utils.call_context  # Missing in Keras 3.x
```

#### Version Mismatch Timeline

- **SHAP 0.46.0** (June 2024): Added Keras 3 support but incomplete
- **TensorFlow 2.18.0** (2024): Bundles Keras 3.5.0 with new module structure  
- **Transformers 4.48.1** (2024): Updated but still has legacy Keras import fallbacks
- **Gap**: SHAP 0.46.0 didn't fully handle the newest Keras 3.x module organization

#### TorchVision Compatibility Issues (July 2025)

**New Root Cause Discovery:**
Even after resolving Keras compatibility, a new class of errors emerged related to TorchVision installations:

1. **Missing TorchVision Operator**: `operator torchvision::nms does not exist`
   - Caused by PyTorch/TorchVision version incompatibility
   - TorchVision installed but with missing or corrupted operators
   - Often due to CUDA version mismatches or incomplete installations

2. **Circular Import Errors**: `partially initialized module 'torchvision' has no attribute 'extension'`
   - Caused by corrupted TorchVision installations
   - TorchVision partially loaded but missing essential components
   - Often due to mixed installation sources (pip vs conda)

**Import Chain Causing TorchVision Issues:**
```python
shap.TreeExplainer() 
‚Üí shap.utils.transformers.is_transformers_lm()
‚Üí transformers.modeling_utils 
‚Üí transformers.image_utils
‚Üí torchvision.transforms.InterpolationMode  # Triggers TorchVision load
‚Üí torchvision.__init__
‚Üí torchvision._meta_registrations  # Fails on corrupted installations
```

---

## Solution Implementation

### Primary Solution: Library Version Update

**Action Taken:** Updated SHAP to the latest version with better compatibility

```bash
conda activate surveyor
pip install --upgrade shap==0.48.0
```

### Why This Fixed the Issue

**SHAP 0.48.0 (June 2025) Improvements:**
- Enhanced compatibility with TensorFlow 2.16+ and Keras 3.x
- Better handling of Keras module reorganization
- Improved transformers library integration
- More robust import error handling

### Additional Solution: Custom Ensemble Model Support

**Issue Discovered:** After resolving Keras compatibility, a new issue emerged where SHAP TreeExplainer couldn't handle custom ensemble models.

**Root Cause:** The splice site prediction system uses custom ensemble classes (`CalibratedSigmoidEnsemble`, `SigmoidEnsemble`, `PerClassCalibratedSigmoidEnsemble`) that wrap underlying XGBoost models. SHAP TreeExplainer only recognizes standard sklearn/XGBoost models.

**Solution Implemented:** Added ensemble model detection and underlying model extraction to all SHAP functions:

```python
def handle_ensemble_model(model):
    """Extract underlying model from custom ensemble wrappers"""
    actual_model = model
    
    if hasattr(model, 'models') and hasattr(model, '__class__'):
        class_name = model.__class__.__name__
        if class_name in ['CalibratedSigmoidEnsemble', 'SigmoidEnsemble', 'PerClassCalibratedSigmoidEnsemble']:
            # Extract underlying binary models
            if hasattr(model, 'get_base_models'):
                binary_models = model.get_base_models()
                actual_model = binary_models[0]  # Use first as representative
            elif hasattr(model, 'models') and len(model.models) > 0:
                actual_model = model.models[0]  # Use first binary model
    
    return actual_model
```

**Applied to Functions:**
- `incremental_shap_importance()`
- `create_memory_efficient_beeswarm_plot()`
- `plot_shap_dependence()`

### TorchVision Compatibility Solutions (July 2025)

**Primary Solution: Fix TorchVision Installation**

The most effective solution is to properly install compatible PyTorch/TorchVision versions:

```bash
# Remove corrupted installations
conda remove torchvision pytorch torchaudio --force
pip uninstall torch torchvision torchaudio -y

# Clean cache
conda clean --all

# Reinstall compatible versions
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
```

**Alternative Solution: Remove TorchVision Entirely**

If TorchVision is not needed, removing it prevents the import conflicts:

```bash
conda remove torchvision --force
pip uninstall torchvision -y
```

**Diagnostic Solution: Comprehensive Testing**

Created `debug_shap_issue.py` to systematically diagnose SHAP/TorchVision compatibility:

```python
def test_pytorch_torchvision_compatibility():
    """Test if PyTorch and TorchVision are compatible."""
    # Test NMS operator specifically
    from torchvision.ops import nms
    # Test with dummy data
    
def test_transformers_import():
    """Test if transformers can be imported without torchvision issues."""
    
def test_shap_patches():
    """Test if our SHAP patches are working."""
    
def test_simple_shap_operation():
    """Test a simple SHAP operation to see where it fails."""
```

### Enhanced Backup Solution: Module-Level Patching

**Updated Implementation:** Enhanced the existing monkey patching with module-level transformers patching:

```python
# CRITICAL FIX: Set comprehensive environment isolation BEFORE importing SHAP
os.environ.update({
    "TRANSFORMERS_OFFLINE": "1",
    "HF_HUB_DISABLE_TELEMETRY": "1", 
    "HF_HUB_OFFLINE": "1",
    "TRANSFORMERS_CACHE": "/tmp/transformers_cache_disabled",
    "CUDA_VISIBLE_DEVICES": "",
    "PYTHONWARNINGS": "ignore",
})

# Import SHAP with protective monkey patching
import shap

# CRITICAL FIX: IMMEDIATELY patch transformers check at module level
def dummy_is_transformers_lm(model):
    """Always return False to bypass transformers check."""
    return False

# Replace the problematic function immediately after SHAP import
from shap.utils import transformers as shap_transformers
shap_transformers.is_transformers_lm = dummy_is_transformers_lm

# ADDITIONAL FALLBACK: Install dummy transformers module if needed
if 'transformers' not in sys.modules:
    sys.modules['transformers'] = dummy_transformers_module
```

**Key Improvement:** The patching now happens at module import time, before any TreeExplainer instantiation, making it more robust.

### Backup Solution: Keras Monkey Patching

**Already Implemented:** The codebase already had comprehensive Keras monkey patching in `shap_incremental.py` as a safety measure:

```python
def _create_keras_internal_mock():
    """Create mocks for both keras.__internal__ and keras.src.engine hierarchies"""
    # Mock keras.__internal__ for older transformers
    # Mock keras.src.engine for newer transformers  
    # Applied at multiple entry points for comprehensive coverage
```

**Coverage:**
- `keras.__internal__` mock with `KerasTensor`, `SparseKerasTensor`, `RaggedKerasTensor`
- `keras.src.engine` mock with `base_layer_utils.call_context`
- Environment variable settings and warning suppression
- Applied in 3 different code paths for complete coverage

---

## Library Compatibility Matrix

### ‚úÖ **Current Working Configuration**

```
Environment: surveyor (conda)
Python: 3.10.13
PyTorch: 2.5.1 ‚Üê Updated July 2025
TorchVision: 0.20.1 ‚Üê Updated July 2025
TensorFlow: 2.18.0
Keras: 3.5.0 (bundled with TensorFlow)
Transformers: 4.48.1
SHAP: 0.48.0 ‚Üê Updated from 0.46.0
```

### üîÑ **Alternative Stable Configurations**

#### Option 1: Conservative Stable (With TorchVision)
```
PyTorch: 2.3.0
TorchVision: 0.18.0
TensorFlow: 2.16.1
Keras: 3.3.3
Transformers: 4.40.0
SHAP: 0.46.0+
```

#### Option 2: Legacy Stable (With TorchVision)
```
PyTorch: 2.1.0
TorchVision: 0.16.0
TensorFlow: 2.15.0
Keras: 2.15.0 (TF-bundled)
Transformers: 4.35.0
SHAP: 0.45.0
```

#### Option 3: No TorchVision (Simplest)
```
TensorFlow: 2.18.0
Keras: 3.5.0 (bundled with TensorFlow)
Transformers: 4.48.1
SHAP: 0.48.0
# TorchVision: Not installed
```

### ‚ùå **Known Problematic Combinations**

```
# Original Keras issues
TensorFlow: 2.18.0 + Keras: 3.5.0 + SHAP: 0.46.0
TensorFlow: 2.16+ + Keras: 3.x + Transformers: 4.21-4.35 + SHAP: <0.46.0

# NEW: TorchVision issues (July 2025)
PyTorch: 2.3.0 + TorchVision: 0.17.2 + Transformers: 4.48.1 + SHAP: 0.48.0
PyTorch: 2.5.1 + TorchVision: 0.17.2 + Transformers: 4.48.1 + SHAP: 0.48.0
# Any PyTorch/TorchVision version mismatch
# Any corrupted TorchVision installation
# Mixed pip/conda TorchVision installations
```

---

## Testing and Verification

### Test Suite Development

Created comprehensive test suite to verify SHAP functionality:

#### Diagnostic Script (debug_shap_issue.py)

**Created July 2025:** Comprehensive diagnostic script to systematically identify SHAP compatibility issues:

```python
def test_pytorch_torchvision_compatibility():
    """Test if PyTorch and TorchVision are compatible."""
    import torch, torchvision
    from torchvision.ops import nms
    # Test NMS operator with dummy data
    
def test_transformers_import():
    """Test if transformers can be imported without torchvision issues."""
    import transformers
    from transformers import modeling_utils
    
def test_shap_patches():
    """Test if our SHAP patches are working."""
    from shap.utils import transformers as shap_transformers
    result = shap_transformers.is_transformers_lm(None)
    assert result is False  # Should be patched
    
def test_simple_shap_operation():
    """Test a simple SHAP operation to see where it fails."""
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X)
```

#### Basic Import Tests
```python
# Test 1: Core library imports
import tensorflow as tf
import keras  
import shap
import transformers

# Test 2: Problematic module paths
import keras.src.engine  # Should exist in Keras 3.x
import keras.__internal__  # Should NOT exist in Keras 3.x

# Test 3: NEW - TorchVision compatibility
import torch
import torchvision
from torchvision.ops import nms  # Critical operator test
```

#### Functional Tests
```python
# Test 4: SHAP TreeExplainer creation
explainer = shap.TreeExplainer(model)

# Test 5: SHAP value calculation  
shap_values = explainer.shap_values(X)

# Test 6: SHAP format handling (new vs old format)
if isinstance(shap_values, np.ndarray) and len(shap_values.shape) == 3:
    shap_vals = shap_values[:, :, 1]  # Handle new format
```

#### Integration Tests
```python
# Test 7: Gene-aware CV SHAP imports
from meta_spliceai.splice_engine.meta_models.evaluation.shap_incremental import (
    run_incremental_shap_analysis,
    incremental_shap_importance
)
```

### Test Results

**Latest Test Results (July 2025):**

#### Working Configuration:
```
PyTorch/TorchVision: ‚úÖ PASS (2.5.1/0.20.1)
Transformers Import: ‚úÖ PASS
SHAP Patches: ‚úÖ PASS
Simple SHAP: ‚úÖ PASS
```

#### Previously Problematic Configuration:
```
PyTorch/TorchVision: ‚ùå FAIL (operator torchvision::nms does not exist)
Transformers Import: ‚ùå FAIL (circular import)
SHAP Patches: ‚úÖ PASS
Simple SHAP: ‚ùå FAIL
```

**Historical Test Results:**
- Basic library imports: OK
- Module structure compatibility: OK  
- TreeExplainer creation: OK
- SHAP value calculation: OK
- Format handling (new 3D array format): OK
- Gene-aware CV integration: OK
- **NEW**: TorchVision compatibility: OK (after fix)
- **NEW**: NMS operator functionality: OK (after fix)

---

## Future Maintenance

### Version Monitoring

**Critical Dependencies to Monitor:**
1. **SHAP**: Watch for updates that improve TensorFlow/Keras compatibility
2. **TensorFlow**: Major version updates may change Keras bundling
3. **Transformers**: Updates may change Keras import behavior
4. **Keras**: Standalone vs TF-bundled version compatibility
5. **NEW - PyTorch/TorchVision**: Version compatibility and operator support
6. **NEW - CUDA**: TorchVision compatibility with CUDA versions

### Maintenance Schedule

**Quarterly Review:**
- Check for SHAP library updates
- Test compatibility with latest TensorFlow releases
- Review transformers library changelog for Keras-related changes
- **NEW**: Monitor PyTorch/TorchVision compatibility matrix
- **NEW**: Run diagnostic script (`debug_shap_issue.py`) to verify all components

**Before Major Updates:**
- Test SHAP functionality in development environment
- Run full gene-aware CV pipeline with SHAP analysis
- Verify feature importance outputs are reasonable (not dummy values)
- **NEW**: Run comprehensive diagnostic script to identify potential issues
- **NEW**: Test TorchVision NMS operator functionality

### Warning Signs

**Indicators of Compatibility Issues:**
- SHAP analysis returning dummy values (0.0001)
- `keras.__internal__` or `keras.src.engine` import errors
- Transformers import failures during SHAP analysis
- Significant performance degradation in SHAP calculations
- **NEW**: `operator torchvision::nms does not exist` errors
- **NEW**: `partially initialized module 'torchvision'` errors
- **NEW**: TorchVision circular import errors

### Diagnostic Protocol

**NEW - Systematic Troubleshooting:**
1. **Run diagnostic script first**: `python debug_shap_issue.py`
2. **Identify failing component**: PyTorch/TorchVision, Transformers, SHAP, or Keras
3. **Apply targeted fix**: 
   - TorchVision issues ‚Üí Fix PyTorch/TorchVision installation
   - Transformers issues ‚Üí Apply module-level patches
   - Keras issues ‚Üí Apply Keras mocks
   - SHAP issues ‚Üí Update SHAP version
4. **Verify fix**: Re-run diagnostic script
5. **Test full pipeline**: Run gene-aware CV with SHAP analysis

### Rollback Strategy

**If New Updates Break SHAP:**
1. **Immediate Fix**: Revert to known working versions
   ```bash
   pip install shap==0.48.0 tensorflow==2.18.0
   conda install pytorch==2.5.1 torchvision==0.20.1 -c pytorch
   ```

2. **TorchVision-Specific Fix**: Address PyTorch/TorchVision compatibility
   ```bash
   conda remove pytorch torchvision torchaudio --force
   conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
   ```

3. **Alternative - Remove TorchVision**: If not needed for core functionality
   ```bash
   conda remove torchvision --force
   pip uninstall torchvision -y
   ```

4. **Extended Fix**: Use enhanced monkey patching approach
   - The existing monkey patch in `shap_incremental.py` provides comprehensive coverage
   - Module-level transformers patching prevents import-time errors
   - Can be extended for new compatibility issues

5. **Conservative Rollback**: Downgrade to stable configuration
   ```bash
   pip install tensorflow==2.16.1 shap==0.46.0 transformers==4.40.0
   conda install pytorch==2.3.0 torchvision==0.18.0 -c pytorch
   ```

---

## Technical Implementation Details

### SHAP Output Format Changes

**New Format (SHAP 0.48.0 with sklearn models):**
```python
# Returns 3D array: (n_samples, n_features, n_classes)
shap_values = explainer.shap_values(X)  # shape: (100, 20, 2)
positive_class_values = shap_values[:, :, 1]  # Extract positive class
```

**Legacy Format (SHAP <0.46.0):**
```python  
# Returns list of 2D arrays for each class
shap_values = explainer.shap_values(X)  # List of length n_classes
positive_class_values = shap_values[1]  # Positive class array
```

### Code Adaptation Required

**Update SHAP value processing code to handle both formats:**
```python
def extract_positive_class_shap_values(shap_values):
    """Extract positive class SHAP values, handling both old and new formats"""
    if isinstance(shap_values, list):
        # Legacy format: list of arrays
        return shap_values[1]  # Positive class
    elif isinstance(shap_values, np.ndarray):
        if len(shap_values.shape) == 3:
            # New format: 3D array (samples, features, classes)
            return shap_values[:, :, 1]  # Positive class
        else:
            # Single class or other format
            return shap_values
    else:
        raise ValueError(f"Unexpected SHAP values format: {type(shap_values)}")
```

### Monkey Patch Implementation

**The existing monkey patch provides coverage for:**
- Multiple Keras module hierarchies (`__internal__`, `src.engine`)
- Mock class creation with proper inheritance
- Environment variable configuration
- Applied at 3 different entry points for redundancy
- Graceful fallback when imports fail

**Monkey patch locations in `shap_incremental.py`:**
1. Module-level execution (lines ~40-120)
2. `_test_shap_import_safety()` function (lines ~844-920) 
3. `run_incremental_shap_analysis()` function (lines ~1020+)

### Performance Considerations

**SHAP 0.48.0 Performance:**
- Similar performance to 0.46.0 for TreeExplainer
- Slightly improved memory management
- Better parallelization support
- More efficient handling of large feature spaces

**Memory Usage:**
- New 3D array format may use slightly more memory
- But provides better type safety and consistency
- Consider memory limits for large feature sets (>1000 features)

---

## Conclusion

The SHAP analysis compatibility issue was successfully resolved through a multi-layered approach:

1. **Initial Resolution (July 9, 2025)**: Updated SHAP from 0.46.0 to 0.48.0 for better TensorFlow 2.18.0 + Keras 3.5.0 compatibility
2. **Secondary Resolution (July 10, 2025)**: Fixed PyTorch/TorchVision compatibility issues that emerged on different machines
3. **Comprehensive Solution**: Implemented module-level transformers patching and systematic diagnostic tools

**Key Technical Discoveries:**
- **TorchVision Dependency**: SHAP ‚Üí Transformers ‚Üí TorchVision import chain causes failures
- **Installation Corruption**: "Installed" packages can be corrupted, causing runtime errors
- **Module-Level Patching**: Earlier patching (at import time) is more robust than function-level patching
- **Systematic Diagnosis**: Automated testing reveals exact failure points for targeted fixes

This resolution maintains the full functionality of the gene-aware cross-validation pipeline while ensuring reliable feature importance analysis through SHAP values across different computing environments.

**Key Success Factors:**
1. **Proper library version management**
2. **Comprehensive testing approach**  
3. **Defensive programming with monkey patches**
4. **Systematic diagnostic tools**
5. **Documentation for future maintenance**
6. **Multi-environment validation**

**Final Architecture:**
- **Primary**: Properly installed PyTorch/TorchVision with compatible versions
- **Fallback**: Module-level transformers patching to prevent import failures
- **Backup**: Comprehensive Keras mocking system
- **Diagnostic**: Automated compatibility testing script

**Next Steps:**
- Monitor library updates quarterly
- Maintain test suite for compatibility verification
- Update documentation as new issues are discovered
- Consider automated compatibility testing in CI/CD pipeline
- **NEW**: Regular TorchVision compatibility validation
- **NEW**: Automated diagnostic script execution in deployment

---

## Incremental SHAP Innovation (January 2025)

### Scalability Enhancement

Beyond compatibility fixes, a major innovation has been implemented to address **Out-of-Memory (OOM) problems** in SHAP analysis:

**Problem Solved:**
- Traditional SHAP analysis fails on large genomic datasets (>100K samples, >10K features)
- Memory requirements: O(N √ó F √ó sizeof(float)) often exceed available RAM
- GPU memory limitations even more restrictive

**Solution: Incremental Processing**
```python
# New incremental approach in shap_incremental.py
from meta_spliceai.splice_engine.meta_models.evaluation.shap_incremental import incremental_shap_importance

# Memory-efficient SHAP analysis
importance = incremental_shap_importance(
    model=model,
    X=large_dataset,
    batch_size=512,        # Configurable memory usage
    background_size=1000,  # Small representative sample
    verbose=True
)
```

**Key Benefits:**
- **Memory Reduction:** From O(N √ó F) to O(batch_size √ó F) - ~2000x improvement for large datasets
- **Scalability:** Handles datasets that were previously impossible to analyze
- **Statistical Equivalence:** Produces identical results to traditional SHAP
- **Configurable:** Adjustable batch sizes based on available memory

**Integration:**
- Fully compatible with existing SHAP compatibility fixes
- Automatic ensemble model detection and handling
- Comprehensive error handling and fallback mechanisms

For detailed usage and technical specifications, see:
- **[incremental_shap_analysis_guide.md](./incremental_shap_analysis_guide.md)** - Complete implementation guide
- **[evaluation_modules_overview.md](./evaluation_modules_overview.md)** - Package overview with usage examples 